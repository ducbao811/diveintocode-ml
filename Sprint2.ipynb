{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "primary-auction",
   "metadata": {},
   "source": [
    "# [Problem 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "catholic-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def scratch_train_test_split(X, y, train_size=0.8, shuffle = True):\n",
    "    \"\"\"Divide the validation data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "      Training data (n_samples, n_features)\n",
    "    y : ndarray\n",
    "      Correct answer value (n_samples,)\n",
    "    train_size : float\n",
    "      Specify what percentage to use as a train (0 < train_size < 1)\n",
    "    Returns\n",
    "    -------\n",
    "    X_train : ndarray\n",
    "      Training data (n_samples, n_features)\n",
    "    X_test : ndarray\n",
    "      Validation data (n_samples, n_features)\n",
    "    y_train : ndarray\n",
    "      Correct answer value of training data (n_samples,)\n",
    "    y_test : ndarray\n",
    "      Correct value of verification data (n_samples,)\n",
    "    \"\"\"    \n",
    "    train_samples_size = int(round(train_size * X.shape[0]))\n",
    "    X_train = X[:train_samples_size,:]\n",
    "    X_test = X[train_samples_size:,:]\n",
    "    y_train = y[:train_samples_size]\n",
    "    y_test = y[train_samples_size:]\n",
    "    if shuffle:\n",
    "        idx_c = np.random.choice(range(X.shape[0]), size=(train_samples_size,),replace=False)\n",
    "        index = np.zeros(X.shape[0],dtype=bool)\n",
    "        index[idx_c] = True\n",
    "        rest = ~index\n",
    "        X_train = X[index,:]\n",
    "        X_test = X[rest,:]\n",
    "        y_train = y[index]\n",
    "        y_test = y[rest]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-empty",
   "metadata": {},
   "source": [
    "**Testing behavior of the self-made splitting method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "considered-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.arange(100).reshape(50,2), np.arange(50)\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y,train_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "younger-mexican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (10, 2)\n",
      "X_test shape: (40, 2)\n",
      "y_train shape: (10,)\n",
      "y_test shape: (40,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('y_test shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bulgarian-consolidation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      " [[ 6  7]\n",
      " [20 21]\n",
      " [22 23]\n",
      " [30 31]\n",
      " [48 49]\n",
      " [50 51]\n",
      " [54 55]\n",
      " [68 69]\n",
      " [78 79]\n",
      " [94 95]]\n"
     ]
    }
   ],
   "source": [
    "print('X_train:\\n {}'.format(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pretty-diagnosis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: [ 3 10 11 15 24 25 27 34 39 47]\n"
     ]
    }
   ],
   "source": [
    "print('y_train: {}'.format(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "devoted-victory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test:\n",
      " [[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]\n",
      " [16 17]\n",
      " [18 19]\n",
      " [24 25]\n",
      " [26 27]\n",
      " [28 29]\n",
      " [32 33]\n",
      " [34 35]\n",
      " [36 37]\n",
      " [38 39]\n",
      " [40 41]\n",
      " [42 43]\n",
      " [44 45]\n",
      " [46 47]\n",
      " [52 53]\n",
      " [56 57]\n",
      " [58 59]\n",
      " [60 61]\n",
      " [62 63]\n",
      " [64 65]\n",
      " [66 67]\n",
      " [70 71]\n",
      " [72 73]\n",
      " [74 75]\n",
      " [76 77]\n",
      " [80 81]\n",
      " [82 83]\n",
      " [84 85]\n",
      " [86 87]\n",
      " [88 89]\n",
      " [90 91]\n",
      " [92 93]\n",
      " [96 97]\n",
      " [98 99]]\n"
     ]
    }
   ],
   "source": [
    "print('X_test:\\n {}'.format(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aging-store",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test:\n",
      " [ 0  1  2  4  5  6  7  8  9 12 13 14 16 17 18 19 20 21 22 23 26 28 29 30\n",
      " 31 32 33 35 36 37 38 40 41 42 43 44 45 46 48 49]\n"
     ]
    }
   ],
   "source": [
    "print('y_test:\\n {}'.format(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-adrian",
   "metadata": {},
   "source": [
    "**Iris dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "loving-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "seventh-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "arabic-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "offensive-deposit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "opposed-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['target'] != 2.0]\n",
    "X_iris = np.array(df.iloc[:,0:4])\n",
    "y_iris = np.array(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "third-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris_train, X_iris_test, y_iris_train, y_iris_test = scratch_train_test_split(X_iris,y_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "expanded-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (80, 4)\n",
      "X_test shape: (20, 4)\n",
      "y_train shape: (80,)\n",
      "y_test shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: {}'.format(X_iris_train.shape))\n",
    "print('X_test shape: {}'.format(X_iris_test.shape))\n",
    "print('y_train shape: {}'.format(y_iris_train.shape))\n",
    "print('y_test shape: {}'.format(y_iris_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-netscape",
   "metadata": {},
   "source": [
    "**Simple Dataset 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "criminal-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, n_samples // 2)\n",
    "f1 = np.random.multivariate_normal(f1, cov, n_samples // 2)\n",
    "X_sample_1 = np.concatenate([f0, f1])\n",
    "y_sample_1 = np.concatenate([\n",
    "    np.full(n_samples // 2, 1),\n",
    "    np.full(n_samples // 2, -1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "defined-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample_1, X_test_sample_1, y_train_sample_1, y_test_sample_1 = scratch_train_test_split(X_sample_1,y_sample_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "medical-surrey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (400, 2)\n",
      "X_test shape: (100, 2)\n",
      "y_train shape: (400,)\n",
      "y_test shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: {}'.format(X_train_sample_1.shape))\n",
    "print('X_test shape: {}'.format(X_test_sample_1.shape))\n",
    "print('y_train shape: {}'.format(y_train_sample_1.shape))\n",
    "print('y_test shape: {}'.format(y_test_sample_1.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-formation",
   "metadata": {},
   "source": [
    "**Sample Dataset 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "flush-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample_2 = np.array([\n",
    "    [-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "    [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "    [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "    [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "    [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "    [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "    [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "    [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "    [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "    [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "    [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "    [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "    [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "    [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "    [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "    [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "    [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "    [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "    [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "    [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ],\n",
    "])\n",
    "y_sample_2 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "becoming-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample_2, X_test_sample_2, y_train_sample_2, y_test_sample_2 = scratch_train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "unlike-laundry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (32, 2)\n",
      "X_test shape: (8, 2)\n",
      "y_train shape: (32,)\n",
      "y_test shape: (8,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: {}'.format(X_train_sample_2.shape))\n",
    "print('X_test shape: {}'.format(X_test_sample_2.shape))\n",
    "print('y_train shape: {}'.format(y_train_sample_2.shape))\n",
    "print('y_test shape: {}'.format(y_test_sample_2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-lesbian",
   "metadata": {},
   "source": [
    "# [Problem 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "secondary-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "differential-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_and_estimator(model,X,y):\n",
    "    \"\"\"\n",
    "        This function is used to perform easy training and estimating process\n",
    "        ----\n",
    "        Input:\n",
    "            model: classifier model\n",
    "            X: dataset\n",
    "            y: labels set\n",
    "        Output:\n",
    "            accury score, precision score, recall score,f1 score\n",
    "    \"\"\"\n",
    "    # Splitting the dataset\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X,y,train_size=0.75)\n",
    "    \n",
    "    clf = make_pipeline(StandardScaler(),model)\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "french-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_solution(X,y):\n",
    "    accuracy_list = []\n",
    "    f1_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    method_name = ['SGD Classifier','SVM','Decision Tree Classifier']\n",
    "    models = [SGDClassifier(loss='log'),SVC(),DecisionTreeClassifier()]\n",
    "    for model in models:\n",
    "        accuracy, precision, recall, f1 = classifier_and_estimator(model, X, y)\n",
    "        accuracy_list.append(accuracy)\n",
    "        f1_list.append(f1)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "    result = pd.DataFrame({\n",
    "        'Accuracy' : accuracy_list,\n",
    "        'Precision': precision_list,\n",
    "        'Recall': recall_list,\n",
    "        'F1': f1_list\n",
    "    },index=method_name)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fossil-quantity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Dataset solution\n",
      "                          Accuracy  Precision  Recall   F1\n",
      "SGD Classifier                 1.0        1.0     1.0  1.0\n",
      "SVM                            1.0        1.0     1.0  1.0\n",
      "Decision Tree Classifier       1.0        1.0     1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Iris Dataset solution')\n",
    "classification_solution(X_iris,y_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "violent-details",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Dataset 1 solution\n",
      "                          Accuracy  Precision  Recall   F1\n",
      "SGD Classifier                 1.0        1.0     1.0  1.0\n",
      "SVM                            1.0        1.0     1.0  1.0\n",
      "Decision Tree Classifier       1.0        1.0     1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Sample Dataset 1 solution')\n",
    "classification_solution(X_sample_1,y_sample_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "threaded-slovenia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Dataset solution\n",
      "                          Accuracy  Precision    Recall        F1\n",
      "SGD Classifier                 0.5   0.333333  0.666667  0.444444\n",
      "SVM                            0.2   0.166667  0.250000  0.200000\n",
      "Decision Tree Classifier       0.8   0.833333  0.833333  0.833333\n"
     ]
    }
   ],
   "source": [
    "print('Iris Dataset solution')\n",
    "classification_solution(X_sample_2,y_sample_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-importance",
   "metadata": {},
   "source": [
    "## Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "offshore-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "needed-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "respected-chinese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "confident-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor() )\n",
    "X = np.array(regression_data[['GrLivArea','YearBuilt']])\n",
    "y = np.array(regression_data['SalePrice'])\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X,y,train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "sealed-truth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error for SDG Regression: 1673432987.2005284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "reg.fit(X_train,y_train)\n",
    "pred = reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test,pred)\n",
    "print('Mean square error for SDG Regression: {}'.format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-dining",
   "metadata": {},
   "source": [
    "# [Problem 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "clinical-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def linear_train_estimate(X,y):\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X,y,train_size=0.75)\n",
    "    reg = make_pipeline(StandardScaler(), LinearRegression() )\n",
    "    reg.fit(X_train,y_train)\n",
    "    pred = reg.predict(X_test)\n",
    "    mse = mean_squared_error(y_test,pred)\n",
    "    print('Mean square error for Linear Regression: {}'.format(mse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "square-billion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error for Linear Regression: 2395562570.0367484\n"
     ]
    }
   ],
   "source": [
    "linear_train_estimate(X,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
